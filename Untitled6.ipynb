{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+4JXEbnD21YmpMUjWf3H4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feuerteufelfw/SOC/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import der Bibs"
      ],
      "metadata": {
        "id": "URKlxtdCBb_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from itertools import product\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "X5crImMmBaNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test GPU unterstützung"
      ],
      "metadata": {
        "id": "ntJy5Va4Bl69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Verwendete Geräte:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "iw0jDY0-BoGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daten laden"
      ],
      "metadata": {
        "id": "exnnkSFYBrWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "mask_train, mask_test = np.isin(y_train, [0,1]), np.isin(y_test, [0,1])\n",
        "x_train, y_train = x_train[mask_train]/255., y_train[mask_train]\n",
        "x_test, y_test = x_test[mask_test]/255., y_test[mask_test]\n",
        "y_train_o, y_test_o = to_categorical(y_train,2), to_categorical(y_test,2)\n"
      ],
      "metadata": {
        "id": "S-Gm4Ai2Bw26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P-l4X4UuV0k",
        "outputId": "ba98c252-4e3b-4cfc-f019-7185c7c8748d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n",
            "Verwendete Geräte: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=adam\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.5921 - val_accuracy: 0.9050 - val_loss: 0.2433\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2697 - val_accuracy: 0.9220 - val_loss: 0.1951\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2228 - val_accuracy: 0.9275 - val_loss: 0.1646\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.1738 - val_accuracy: 0.9320 - val_loss: 0.1640\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.1536 - val_accuracy: 0.9360 - val_loss: 0.1488\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1347 - val_accuracy: 0.9375 - val_loss: 0.1394\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1166 - val_accuracy: 0.9330 - val_loss: 0.1512\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1071 - val_accuracy: 0.9450 - val_loss: 0.1228\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0819 - val_accuracy: 0.9420 - val_loss: 0.1317\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0718 - val_accuracy: 0.9490 - val_loss: 0.1235\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0666 - val_accuracy: 0.9470 - val_loss: 0.1207\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0693 - val_accuracy: 0.9515 - val_loss: 0.1254\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0478 - val_accuracy: 0.9500 - val_loss: 0.1323\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0473 - val_accuracy: 0.9515 - val_loss: 0.1175\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0520 - val_accuracy: 0.9575 - val_loss: 0.1158\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0354 - val_accuracy: 0.9480 - val_loss: 0.1399\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0393 - val_accuracy: 0.9465 - val_loss: 0.1293\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0342 - val_accuracy: 0.9510 - val_loss: 0.1285\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9618 - loss: 0.0966\n",
            "--> accuracy: 0.9575 after 18 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=sgd\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.9016 - val_accuracy: 0.8380 - val_loss: 0.3909\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5260 - val_accuracy: 0.8445 - val_loss: 0.3541\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.4382 - val_accuracy: 0.8630 - val_loss: 0.3273\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4117 - val_accuracy: 0.8720 - val_loss: 0.3102\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.3924 - val_accuracy: 0.8820 - val_loss: 0.2953\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3811 - val_accuracy: 0.8855 - val_loss: 0.2889\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.3524 - val_accuracy: 0.8880 - val_loss: 0.2787\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3586 - val_accuracy: 0.8905 - val_loss: 0.2680\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3460 - val_accuracy: 0.8910 - val_loss: 0.2647\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3216 - val_accuracy: 0.9000 - val_loss: 0.2562\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3175 - val_accuracy: 0.8990 - val_loss: 0.2519\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3128 - val_accuracy: 0.9015 - val_loss: 0.2465\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3080 - val_accuracy: 0.9040 - val_loss: 0.2387\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.3081 - val_accuracy: 0.9050 - val_loss: 0.2358\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.2971 - val_accuracy: 0.9100 - val_loss: 0.2311\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.2867 - val_accuracy: 0.9100 - val_loss: 0.2291\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.2895 - val_accuracy: 0.9085 - val_loss: 0.2255\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2899 - val_accuracy: 0.9095 - val_loss: 0.2208\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.2795 - val_accuracy: 0.9125 - val_loss: 0.2183\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2691 - val_accuracy: 0.9145 - val_loss: 0.2138\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2653 - val_accuracy: 0.9165 - val_loss: 0.2108\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8881 - loss: 0.2609 - val_accuracy: 0.9170 - val_loss: 0.2087\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2599 - val_accuracy: 0.9185 - val_loss: 0.2077\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2594 - val_accuracy: 0.9185 - val_loss: 0.2029\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2502 - val_accuracy: 0.9205 - val_loss: 0.2016\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2636 - val_accuracy: 0.9170 - val_loss: 0.2027\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2452 - val_accuracy: 0.9185 - val_loss: 0.1963\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2327 - val_accuracy: 0.9215 - val_loss: 0.1951\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2236 - val_accuracy: 0.9250 - val_loss: 0.1929\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2329 - val_accuracy: 0.9255 - val_loss: 0.1899\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9295 - loss: 0.1817\n",
            "--> accuracy: 0.9255 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=rmsprop\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.5342 - val_accuracy: 0.8970 - val_loss: 0.2547\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.2758 - val_accuracy: 0.9235 - val_loss: 0.1938\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2435 - val_accuracy: 0.9330 - val_loss: 0.1962\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.1952 - val_accuracy: 0.9245 - val_loss: 0.2077\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1681 - val_accuracy: 0.9455 - val_loss: 0.1540\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1428 - val_accuracy: 0.9490 - val_loss: 0.1639\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1523 - val_accuracy: 0.9435 - val_loss: 0.1845\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1285 - val_accuracy: 0.9550 - val_loss: 0.1472\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1225 - val_accuracy: 0.9505 - val_loss: 0.1718\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1112 - val_accuracy: 0.9475 - val_loss: 0.1775\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0967 - val_accuracy: 0.9580 - val_loss: 0.1743\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1212\n",
            "--> accuracy: 0.9550 after 11 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=adagrad\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.9628 - val_accuracy: 0.8245 - val_loss: 0.4015\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.6471 - val_accuracy: 0.8445 - val_loss: 0.3592\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7593 - loss: 0.5826 - val_accuracy: 0.8485 - val_loss: 0.3435\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.5264 - val_accuracy: 0.8600 - val_loss: 0.3313\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5197 - val_accuracy: 0.8625 - val_loss: 0.3231\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4990 - val_accuracy: 0.8660 - val_loss: 0.3181\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4783 - val_accuracy: 0.8680 - val_loss: 0.3138\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4820 - val_accuracy: 0.8700 - val_loss: 0.3102\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4611 - val_accuracy: 0.8740 - val_loss: 0.3085\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4403 - val_accuracy: 0.8755 - val_loss: 0.3057\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4417 - val_accuracy: 0.8760 - val_loss: 0.3039\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.4165 - val_accuracy: 0.8790 - val_loss: 0.3013\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4317 - val_accuracy: 0.8800 - val_loss: 0.3000\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.4349 - val_accuracy: 0.8785 - val_loss: 0.2988\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.4202 - val_accuracy: 0.8815 - val_loss: 0.2962\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.3970 - val_accuracy: 0.8820 - val_loss: 0.2935\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3994 - val_accuracy: 0.8835 - val_loss: 0.2936\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3949 - val_accuracy: 0.8845 - val_loss: 0.2921\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3936 - val_accuracy: 0.8860 - val_loss: 0.2900\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3944 - val_accuracy: 0.8855 - val_loss: 0.2882\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3902 - val_accuracy: 0.8855 - val_loss: 0.2874\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.3905 - val_accuracy: 0.8860 - val_loss: 0.2872\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3710 - val_accuracy: 0.8860 - val_loss: 0.2861\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3724 - val_accuracy: 0.8855 - val_loss: 0.2845\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3794 - val_accuracy: 0.8885 - val_loss: 0.2843\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3848 - val_accuracy: 0.8880 - val_loss: 0.2832\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3644 - val_accuracy: 0.8895 - val_loss: 0.2810\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.3706 - val_accuracy: 0.8890 - val_loss: 0.2810\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.3721 - val_accuracy: 0.8890 - val_loss: 0.2797\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3557 - val_accuracy: 0.8905 - val_loss: 0.2790\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8987 - loss: 0.2743\n",
            "--> accuracy: 0.8905 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(5, 5), optimizer=adam\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.5787 - val_accuracy: 0.8965 - val_loss: 0.2452\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.2841 - val_accuracy: 0.8780 - val_loss: 0.2832\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.2303 - val_accuracy: 0.9200 - val_loss: 0.1983\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.1736 - val_accuracy: 0.9115 - val_loss: 0.2152\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.1505 - val_accuracy: 0.9295 - val_loss: 0.1644\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9535 - loss: 0.1196 - val_accuracy: 0.9365 - val_loss: 0.1469\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1050 - val_accuracy: 0.9505 - val_loss: 0.1298\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.0940 - val_accuracy: 0.9505 - val_loss: 0.1252\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0761 - val_accuracy: 0.9480 - val_loss: 0.1317\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.0694 - val_accuracy: 0.9525 - val_loss: 0.1261\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0517 - val_accuracy: 0.9500 - val_loss: 0.1341\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9503 - loss: 0.1225\n",
            "--> accuracy: 0.9505 after 11 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(5, 5), optimizer=sgd\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6638 - loss: 0.8498 - val_accuracy: 0.8310 - val_loss: 0.3687\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.5083 - val_accuracy: 0.8465 - val_loss: 0.3372\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4489 - val_accuracy: 0.8585 - val_loss: 0.3190\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4095 - val_accuracy: 0.8670 - val_loss: 0.2972\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3735 - val_accuracy: 0.8760 - val_loss: 0.2892\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.3647 - val_accuracy: 0.8800 - val_loss: 0.2810\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8479 - loss: 0.3407 - val_accuracy: 0.8755 - val_loss: 0.2789\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3229 - val_accuracy: 0.8825 - val_loss: 0.2675\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3122 - val_accuracy: 0.8825 - val_loss: 0.2624\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3088 - val_accuracy: 0.8865 - val_loss: 0.2506\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.3070 - val_accuracy: 0.8920 - val_loss: 0.2444\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.2926 - val_accuracy: 0.8925 - val_loss: 0.2431\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2935 - val_accuracy: 0.8920 - val_loss: 0.2423\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.2831 - val_accuracy: 0.9000 - val_loss: 0.2282\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.2842 - val_accuracy: 0.9040 - val_loss: 0.2265\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.2703 - val_accuracy: 0.9055 - val_loss: 0.2173\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.2743 - val_accuracy: 0.9050 - val_loss: 0.2176\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8916 - loss: 0.2586 - val_accuracy: 0.9095 - val_loss: 0.2162\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2506 - val_accuracy: 0.9080 - val_loss: 0.2122\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2475 - val_accuracy: 0.9065 - val_loss: 0.2096\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2467 - val_accuracy: 0.9150 - val_loss: 0.1987\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2472 - val_accuracy: 0.9115 - val_loss: 0.1996\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2327 - val_accuracy: 0.9090 - val_loss: 0.1990\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2362 - val_accuracy: 0.9110 - val_loss: 0.1955\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2363 - val_accuracy: 0.9205 - val_loss: 0.1877\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9053 - loss: 0.2312 - val_accuracy: 0.9175 - val_loss: 0.1867\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2258 - val_accuracy: 0.9110 - val_loss: 0.1888\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.2239 - val_accuracy: 0.9165 - val_loss: 0.1800\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2141 - val_accuracy: 0.9210 - val_loss: 0.1790\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2139 - val_accuracy: 0.9205 - val_loss: 0.1773\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.1733\n",
            "--> accuracy: 0.9205 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(5, 5), optimizer=rmsprop\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.5513 - val_accuracy: 0.8810 - val_loss: 0.2754\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.3064 - val_accuracy: 0.9190 - val_loss: 0.2097\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.2669 - val_accuracy: 0.9315 - val_loss: 0.1688\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9288 - loss: 0.2024 - val_accuracy: 0.9355 - val_loss: 0.1688\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.1839 - val_accuracy: 0.9260 - val_loss: 0.2079\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.1836 - val_accuracy: 0.9410 - val_loss: 0.1790\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9320 - loss: 0.1606\n",
            "--> accuracy: 0.9315 after 6 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(5, 5), optimizer=adagrad\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6346 - loss: 1.0904 - val_accuracy: 0.8290 - val_loss: 0.4353\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.6618 - val_accuracy: 0.8430 - val_loss: 0.3885\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.5814 - val_accuracy: 0.8510 - val_loss: 0.3698\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.5506 - val_accuracy: 0.8520 - val_loss: 0.3572\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.5116 - val_accuracy: 0.8580 - val_loss: 0.3462\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.5003 - val_accuracy: 0.8625 - val_loss: 0.3386\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.4787 - val_accuracy: 0.8620 - val_loss: 0.3327\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7978 - loss: 0.4744 - val_accuracy: 0.8645 - val_loss: 0.3279\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.4389 - val_accuracy: 0.8660 - val_loss: 0.3232\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4401 - val_accuracy: 0.8700 - val_loss: 0.3191\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4401 - val_accuracy: 0.8735 - val_loss: 0.3167\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.4294 - val_accuracy: 0.8760 - val_loss: 0.3134\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.4270 - val_accuracy: 0.8750 - val_loss: 0.3101\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.4036 - val_accuracy: 0.8770 - val_loss: 0.3073\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4155 - val_accuracy: 0.8760 - val_loss: 0.3048\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.4053 - val_accuracy: 0.8780 - val_loss: 0.3032\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.3964 - val_accuracy: 0.8785 - val_loss: 0.3015\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.4001 - val_accuracy: 0.8810 - val_loss: 0.3001\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3789 - val_accuracy: 0.8795 - val_loss: 0.2976\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3925 - val_accuracy: 0.8805 - val_loss: 0.2960\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8380 - loss: 0.3925 - val_accuracy: 0.8820 - val_loss: 0.2944\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3863 - val_accuracy: 0.8815 - val_loss: 0.2931\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.3760 - val_accuracy: 0.8810 - val_loss: 0.2910\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8433 - loss: 0.3650 - val_accuracy: 0.8810 - val_loss: 0.2900\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.3642 - val_accuracy: 0.8835 - val_loss: 0.2882\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.3758 - val_accuracy: 0.8840 - val_loss: 0.2867\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8447 - loss: 0.3667 - val_accuracy: 0.8830 - val_loss: 0.2858\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3573 - val_accuracy: 0.8840 - val_loss: 0.2837\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.3781 - val_accuracy: 0.8855 - val_loss: 0.2824\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3563 - val_accuracy: 0.8845 - val_loss: 0.2810\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.2842\n",
            "--> accuracy: 0.8845 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(3, 3), optimizer=adam\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4936 - val_accuracy: 0.9150 - val_loss: 0.2102\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2312 - val_accuracy: 0.9145 - val_loss: 0.2085\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1883 - val_accuracy: 0.9315 - val_loss: 0.1567\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1356 - val_accuracy: 0.9420 - val_loss: 0.1466\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1203 - val_accuracy: 0.9415 - val_loss: 0.1436\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0959 - val_accuracy: 0.9490 - val_loss: 0.1232\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0871 - val_accuracy: 0.9500 - val_loss: 0.1300\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0627 - val_accuracy: 0.9495 - val_loss: 0.1339\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0666 - val_accuracy: 0.9540 - val_loss: 0.1410\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.1034\n",
            "--> accuracy: 0.9490 after 9 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(3, 3), optimizer=sgd\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.8299 - val_accuracy: 0.8685 - val_loss: 0.3222\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4410 - val_accuracy: 0.8795 - val_loss: 0.2836\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8281 - loss: 0.3821 - val_accuracy: 0.8850 - val_loss: 0.2722\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3609 - val_accuracy: 0.8910 - val_loss: 0.2568\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3276 - val_accuracy: 0.8945 - val_loss: 0.2529\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.3157 - val_accuracy: 0.9005 - val_loss: 0.2352\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 0.2951 - val_accuracy: 0.9015 - val_loss: 0.2302\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.2751 - val_accuracy: 0.9010 - val_loss: 0.2242\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2791 - val_accuracy: 0.9085 - val_loss: 0.2143\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8939 - loss: 0.2577 - val_accuracy: 0.9090 - val_loss: 0.2121\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.2685 - val_accuracy: 0.9105 - val_loss: 0.2030\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2563 - val_accuracy: 0.9150 - val_loss: 0.1988\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8945 - loss: 0.2452 - val_accuracy: 0.9150 - val_loss: 0.1933\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2400 - val_accuracy: 0.9150 - val_loss: 0.1882\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.2346 - val_accuracy: 0.9180 - val_loss: 0.1844\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.2220 - val_accuracy: 0.9260 - val_loss: 0.1796\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2120 - val_accuracy: 0.9225 - val_loss: 0.1779\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2136 - val_accuracy: 0.9280 - val_loss: 0.1751\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.2188 - val_accuracy: 0.9240 - val_loss: 0.1734\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2119 - val_accuracy: 0.9290 - val_loss: 0.1691\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2083 - val_accuracy: 0.9320 - val_loss: 0.1653\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.1874 - val_accuracy: 0.9340 - val_loss: 0.1643\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1892 - val_accuracy: 0.9330 - val_loss: 0.1629\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.1953 - val_accuracy: 0.9340 - val_loss: 0.1604\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1871 - val_accuracy: 0.9330 - val_loss: 0.1633\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.1749 - val_accuracy: 0.9365 - val_loss: 0.1569\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.1824 - val_accuracy: 0.9355 - val_loss: 0.1554\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1784 - val_accuracy: 0.9380 - val_loss: 0.1528\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1863 - val_accuracy: 0.9355 - val_loss: 0.1521\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 0.1703 - val_accuracy: 0.9355 - val_loss: 0.1528\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9373 - loss: 0.1409\n",
            "--> accuracy: 0.9355 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(3, 3), optimizer=rmsprop\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.5107 - val_accuracy: 0.9145 - val_loss: 0.2092\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2793 - val_accuracy: 0.9190 - val_loss: 0.2106\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2257 - val_accuracy: 0.9265 - val_loss: 0.2175\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.1932 - val_accuracy: 0.9345 - val_loss: 0.1898\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1809 - val_accuracy: 0.9475 - val_loss: 0.1710\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1444 - val_accuracy: 0.9415 - val_loss: 0.2172\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.1304 - val_accuracy: 0.9470 - val_loss: 0.1792\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.1179 - val_accuracy: 0.9515 - val_loss: 0.1827\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.1520\n",
            "--> accuracy: 0.9475 after 8 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(3, 3), optimizer=adagrad\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6926 - loss: 0.7989 - val_accuracy: 0.8515 - val_loss: 0.3500\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.4895 - val_accuracy: 0.8605 - val_loss: 0.3247\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4418 - val_accuracy: 0.8700 - val_loss: 0.3124\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4111 - val_accuracy: 0.8705 - val_loss: 0.3033\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.4032 - val_accuracy: 0.8710 - val_loss: 0.2958\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3856 - val_accuracy: 0.8790 - val_loss: 0.2892\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.3718 - val_accuracy: 0.8770 - val_loss: 0.2852\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8377 - loss: 0.3618 - val_accuracy: 0.8820 - val_loss: 0.2811\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3577 - val_accuracy: 0.8805 - val_loss: 0.2772\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.3517 - val_accuracy: 0.8835 - val_loss: 0.2730\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.3407 - val_accuracy: 0.8820 - val_loss: 0.2706\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.3323 - val_accuracy: 0.8880 - val_loss: 0.2684\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8609 - loss: 0.3233 - val_accuracy: 0.8870 - val_loss: 0.2653\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.3474 - val_accuracy: 0.8885 - val_loss: 0.2634\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8511 - loss: 0.3292 - val_accuracy: 0.8905 - val_loss: 0.2608\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3235 - val_accuracy: 0.8930 - val_loss: 0.2579\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3120 - val_accuracy: 0.8950 - val_loss: 0.2559\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.3124 - val_accuracy: 0.8955 - val_loss: 0.2531\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.3251 - val_accuracy: 0.8945 - val_loss: 0.2516\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2948 - val_accuracy: 0.8965 - val_loss: 0.2495\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8602 - loss: 0.3183 - val_accuracy: 0.8950 - val_loss: 0.2487\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.2995 - val_accuracy: 0.8985 - val_loss: 0.2474\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3066 - val_accuracy: 0.9010 - val_loss: 0.2449\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.3112 - val_accuracy: 0.9005 - val_loss: 0.2437\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8736 - loss: 0.3047 - val_accuracy: 0.9015 - val_loss: 0.2422\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.2907 - val_accuracy: 0.9010 - val_loss: 0.2420\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 0.2974 - val_accuracy: 0.9020 - val_loss: 0.2400\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2912 - val_accuracy: 0.9035 - val_loss: 0.2372\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.2812 - val_accuracy: 0.9045 - val_loss: 0.2370\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.2882 - val_accuracy: 0.9045 - val_loss: 0.2356\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9059 - loss: 0.2279\n",
            "--> accuracy: 0.9045 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(5, 5), optimizer=adam\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5050 - val_accuracy: 0.8885 - val_loss: 0.2629\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2434 - val_accuracy: 0.9280 - val_loss: 0.1677\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.1723 - val_accuracy: 0.9300 - val_loss: 0.1563\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.1458 - val_accuracy: 0.9320 - val_loss: 0.1546\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9549 - loss: 0.1186 - val_accuracy: 0.9510 - val_loss: 0.1266\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.0937 - val_accuracy: 0.9505 - val_loss: 0.1379\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0747 - val_accuracy: 0.9490 - val_loss: 0.1418\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0608 - val_accuracy: 0.9475 - val_loss: 0.1520\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9563 - loss: 0.1189\n",
            "--> accuracy: 0.9510 after 8 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(5, 5), optimizer=sgd\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7025 - loss: 0.7411 - val_accuracy: 0.8505 - val_loss: 0.3484\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4301 - val_accuracy: 0.8615 - val_loss: 0.3201\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.3775 - val_accuracy: 0.8750 - val_loss: 0.2887\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 0.3548 - val_accuracy: 0.8815 - val_loss: 0.2709\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3348 - val_accuracy: 0.8910 - val_loss: 0.2581\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.3071 - val_accuracy: 0.8960 - val_loss: 0.2477\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.2967 - val_accuracy: 0.9030 - val_loss: 0.2365\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2863 - val_accuracy: 0.8960 - val_loss: 0.2434\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.2762 - val_accuracy: 0.9090 - val_loss: 0.2215\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.2614 - val_accuracy: 0.9090 - val_loss: 0.2106\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.2452 - val_accuracy: 0.9095 - val_loss: 0.2094\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2459 - val_accuracy: 0.9125 - val_loss: 0.2072\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.2274 - val_accuracy: 0.9185 - val_loss: 0.2017\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2219 - val_accuracy: 0.9170 - val_loss: 0.2009\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2174 - val_accuracy: 0.9200 - val_loss: 0.1922\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.2107 - val_accuracy: 0.9120 - val_loss: 0.2068\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2023 - val_accuracy: 0.9220 - val_loss: 0.1814\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.1934 - val_accuracy: 0.9260 - val_loss: 0.1815\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.1894 - val_accuracy: 0.9240 - val_loss: 0.1769\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9219 - loss: 0.1936 - val_accuracy: 0.9280 - val_loss: 0.1722\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.1762 - val_accuracy: 0.9245 - val_loss: 0.1695\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.1773 - val_accuracy: 0.9350 - val_loss: 0.1669\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1730 - val_accuracy: 0.9360 - val_loss: 0.1627\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.1699 - val_accuracy: 0.9320 - val_loss: 0.1749\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.1639 - val_accuracy: 0.9340 - val_loss: 0.1655\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1551 - val_accuracy: 0.9330 - val_loss: 0.1608\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9380 - loss: 0.1511 - val_accuracy: 0.9375 - val_loss: 0.1560\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.1477 - val_accuracy: 0.9335 - val_loss: 0.1562\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1457 - val_accuracy: 0.9380 - val_loss: 0.1532\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.1419 - val_accuracy: 0.9420 - val_loss: 0.1522\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1462\n",
            "--> accuracy: 0.9420 after 30 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(5, 5), optimizer=rmsprop\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.5345 - val_accuracy: 0.8690 - val_loss: 0.3588\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2943 - val_accuracy: 0.9290 - val_loss: 0.2026\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2401 - val_accuracy: 0.9105 - val_loss: 0.2497\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1921 - val_accuracy: 0.9000 - val_loss: 0.2721\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.1687 - val_accuracy: 0.9365 - val_loss: 0.1546\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.1480 - val_accuracy: 0.9425 - val_loss: 0.2046\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1278 - val_accuracy: 0.9400 - val_loss: 0.2099\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1199 - val_accuracy: 0.9425 - val_loss: 0.1737\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9421 - loss: 0.1285\n",
            "--> accuracy: 0.9365 after 8 epochs\n",
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(64, 128), kernel_size=(5, 5), optimizer=adagrad\n",
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7007 - loss: 0.7149 - val_accuracy: 0.8495 - val_loss: 0.3444\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4616 - val_accuracy: 0.8630 - val_loss: 0.3162\n",
            "Epoch 3/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.4292 - val_accuracy: 0.8680 - val_loss: 0.3015\n",
            "Epoch 4/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.4144 - val_accuracy: 0.8725 - val_loss: 0.2913\n",
            "Epoch 5/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.3762 - val_accuracy: 0.8750 - val_loss: 0.2848\n",
            "Epoch 6/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.3687 - val_accuracy: 0.8810 - val_loss: 0.2776\n",
            "Epoch 7/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3638 - val_accuracy: 0.8830 - val_loss: 0.2749\n",
            "Epoch 8/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3483 - val_accuracy: 0.8870 - val_loss: 0.2692\n",
            "Epoch 9/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.3466 - val_accuracy: 0.8910 - val_loss: 0.2643\n",
            "Epoch 10/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3238 - val_accuracy: 0.8915 - val_loss: 0.2615\n",
            "Epoch 11/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.3371 - val_accuracy: 0.8900 - val_loss: 0.2574\n",
            "Epoch 12/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3230 - val_accuracy: 0.8920 - val_loss: 0.2526\n",
            "Epoch 13/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3288 - val_accuracy: 0.8955 - val_loss: 0.2505\n",
            "Epoch 14/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.3129 - val_accuracy: 0.8920 - val_loss: 0.2497\n",
            "Epoch 15/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.3109 - val_accuracy: 0.8965 - val_loss: 0.2452\n",
            "Epoch 16/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3034 - val_accuracy: 0.8985 - val_loss: 0.2423\n",
            "Epoch 17/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.3006 - val_accuracy: 0.8990 - val_loss: 0.2407\n",
            "Epoch 18/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.2858 - val_accuracy: 0.9010 - val_loss: 0.2390\n",
            "Epoch 19/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.3056 - val_accuracy: 0.9005 - val_loss: 0.2359\n",
            "Epoch 20/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 0.2905 - val_accuracy: 0.9010 - val_loss: 0.2335\n",
            "Epoch 21/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2986 - val_accuracy: 0.9045 - val_loss: 0.2315\n",
            "Epoch 22/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8826 - loss: 0.2909 - val_accuracy: 0.9050 - val_loss: 0.2304\n",
            "Epoch 23/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2814 - val_accuracy: 0.9055 - val_loss: 0.2297\n",
            "Epoch 24/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.2799 - val_accuracy: 0.9055 - val_loss: 0.2294\n",
            "Epoch 25/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8840 - loss: 0.2687 - val_accuracy: 0.9065 - val_loss: 0.2266\n",
            "Epoch 26/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2846 - val_accuracy: 0.9045 - val_loss: 0.2246\n",
            "Epoch 27/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.2806 - val_accuracy: 0.9060 - val_loss: 0.2241\n",
            "Epoch 28/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2785 - val_accuracy: 0.9050 - val_loss: 0.2216\n",
            "Epoch 29/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.2756 - val_accuracy: 0.9060 - val_loss: 0.2209\n",
            "Epoch 30/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2770 - val_accuracy: 0.9075 - val_loss: 0.2193\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9054 - loss: 0.2188\n",
            "--> accuracy: 0.9075 after 30 epochs\n",
            "\n",
            "Beste Kombination: (0.3, 0.0001, 8, (32, 64), (3, 3), 'adam', 0.9574999809265137, 18)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# === Parameter ===\n",
        "dropouts = [ 0.3]\n",
        "learning_rates = [1e-4]\n",
        "batch_sizes = [8]\n",
        "filters_list = [(32,64), (64,128)]  # mehrschichtig\n",
        "kernel_sizes = [(3,3), (5,5)]  # verschiedene Kernelgrößen\n",
        "optimizers = ['adam', 'sgd', 'rmsprop', 'adagrad']\n",
        "epochs = 30\n",
        "\n",
        "# === Model-Builder ===\n",
        "def build_model(dp, lr, filters, kernel_size, optimizer_name):\n",
        "    optimizer_dict = {\n",
        "        'adam': tf.keras.optimizers.Adam(lr),\n",
        "        'sgd': tf.keras.optimizers.SGD(lr),\n",
        "        'rmsprop': tf.keras.optimizers.RMSprop(lr),\n",
        "        'adagrad': tf.keras.optimizers.Adagrad(lr)\n",
        "    }\n",
        "    model = Sequential([\n",
        "        Conv2D(filters[0], kernel_size, activation='relu',padding='same', input_shape=(32,32,3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(filters[1], kernel_size, activation='relu',padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dropout(dp),\n",
        "        Dense(64, activation='relu'),  # größere Dense-Schicht\n",
        "        Dropout(dp),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer_dict[optimizer_name], loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# === EarlyStopping ===\n",
        "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brute-Force intelligent Parrameter ermitteln"
      ],
      "metadata": {
        "id": "Wwg0Tf5HB7Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "for dp, lr, bs, filters, ks, opt in product(dropouts, learning_rates, batch_sizes, filters_list, kernel_sizes, optimizers):\n",
        "    print(f'Testing: dp={dp}, lr={lr}, bs={bs}, filters={filters}, kernel_size={ks}, optimizer={opt}')\n",
        "    model = build_model(dp, lr, filters, ks, opt)\n",
        "    history = model.fit(x_train, y_train_o,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=bs,\n",
        "                        validation_data=(x_test, y_test_o),\n",
        "                        callbacks=[es], verbose=1)\n",
        "    acc = model.evaluate(x_test, y_test_o, verbose=1)[1]\n",
        "    epochs_run = len(history.history['loss'])\n",
        "    results.append((dp, lr, bs, filters, ks, opt, acc, epochs_run))\n",
        "    print(f'--> accuracy: {acc:.4f} after {epochs_run} epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "Nz4V9YeBB4kS",
        "outputId": "eea5a305-da85-4058-bc84-27bcb7288d9b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=adam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.5396 - val_accuracy: 0.9065 - val_loss: 0.2336\n",
            "Epoch 2/30\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2581 - val_accuracy: 0.9330 - val_loss: 0.1699\n",
            "Epoch 3/30\n",
            "\u001b[1m 309/1250\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1976"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2124359112>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Testing: dp={dp}, lr={lr}, bs={bs}, filters={filters}, kernel_size={ks}, optimizer={opt}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     history = model.fit(x_train, y_train_o,\n\u001b[0m\u001b[1;32m      6\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_train_batch_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36m_on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"Called at the end of a training batch in `fit` methods.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bestes Ergebnis anzeigen"
      ],
      "metadata": {
        "id": "GORBdLjECKAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best = max(results, key=lambda x: x[-2])\n",
        "print('\\nBeste Kombination:', best)"
      ],
      "metadata": {
        "id": "ASsjVATGBaGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainieren des Modells"
      ],
      "metadata": {
        "id": "2uNaDKmlBPLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dp=0.3\n",
        "lr=0.0001\n",
        "bs=8\n",
        "filters=(32, 64)\n",
        "ks=(3, 3)\n",
        "opt= \"adam\"\n",
        "epoche=18\n",
        "print(f'Testing: dp={dp}, lr={lr}, bs={bs}, filters={filters}, kernel_size={ks}, optimizer={opt}')\n",
        "model = build_model(dp, lr, filters, ks, opt)\n",
        "history = model.fit(x_train, y_train_o,\n",
        "                    epochs=epoche,\n",
        "                    batch_size=bs,\n",
        "                    validation_data=(x_test, y_test_o),\n",
        "                    callbacks=[es], verbose=1)\n",
        "acc = model.evaluate(x_test, y_test_o, verbose=1)[1]\n",
        "epochs_run = len(history.history['loss'])\n",
        "results.append((dp, lr, bs, filters, ks, opt, acc, epochs_run))\n",
        "print(f'--> accuracy: {acc:.4f} after {epochs_run} epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4enWmCLQ5Q6b",
        "outputId": "6d545ac8-5695-4cda-eed3-86173eb10513"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: dp=0.3, lr=0.0001, bs=8, filters=(32, 64), kernel_size=(3, 3), optimizer=adam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.5444 - val_accuracy: 0.9020 - val_loss: 0.2236\n",
            "Epoch 2/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2439 - val_accuracy: 0.9260 - val_loss: 0.1775\n",
            "Epoch 3/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.1931 - val_accuracy: 0.9355 - val_loss: 0.1606\n",
            "Epoch 4/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.1462 - val_accuracy: 0.9370 - val_loss: 0.1518\n",
            "Epoch 5/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.1152 - val_accuracy: 0.9465 - val_loss: 0.1266\n",
            "Epoch 6/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.0970 - val_accuracy: 0.9450 - val_loss: 0.1302\n",
            "Epoch 7/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0830 - val_accuracy: 0.9445 - val_loss: 0.1295\n",
            "Epoch 8/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0785 - val_accuracy: 0.9475 - val_loss: 0.1256\n",
            "Epoch 9/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0624 - val_accuracy: 0.9515 - val_loss: 0.1277\n",
            "Epoch 10/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0585 - val_accuracy: 0.9535 - val_loss: 0.1268\n",
            "Epoch 11/18\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0473 - val_accuracy: 0.9460 - val_loss: 0.1336\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9551 - loss: 0.1070\n",
            "--> accuracy: 0.9475 after 11 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testen mit eigenen Bildern"
      ],
      "metadata": {
        "id": "KOWdlJBNBTIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "urls = {\n",
        "    \"img1\":\"https://s2.best-wallpaper.net/wallpaper/3840x2160/1810/Passenger-plane-front-view-flight-clouds_3840x2160.jpg\",\n",
        "    \"img2\":\"https://media.istockphoto.com/id/92042438/de/foto/boeing-737-800-passagier-jet.jpg?s=2048x2048&w=is&k=20&c=xcX2SOzd2vlnqT6jQNHav2JxjxIGvNl84S1Ny-7zzXk=\",\n",
        "    \"img3\":\"https://imgs.search.brave.com/sNB5NmpCutgkqnzyRiGRaqIXdaiN25TQKX7WQSoynIc/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly93d3cu/YXV0b3Njb3V0MjQu/ZGUvY21zLWNvbnRl/bnQtYXNzZXRzLzNS/S1MyZjA4clJyVldy/a0JzQURUZFgtZDEz/ZWQ2MDdmZWMyMWI5/YTUyMmI0YTFiYTZi/OTA5OGItZmlhdC1w/dW50by1zaWRlLTEx/MDAuanBn\",\n",
        "    \"img4\":\"https://www.fahrzeugbilder.de/1200/ifa-l60-acn-bj-1989-203857.jpg\"}\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "for i, (name, url) in enumerate(urls.items()):\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=10)\n",
        "        resp.raise_for_status()\n",
        "        img = Image.open(BytesIO(resp.content)).convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler bei {name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    img_resized = img.resize((32, 32))\n",
        "    x = np.array(img_resized) / 255.0\n",
        "    x_batch = x.reshape(1, 32, 32, 3)\n",
        "\n",
        "    pred = model.predict(x_batch)\n",
        "    label = np.argmax(pred, axis=1)[0]\n",
        "    proba = pred[0, label]\n",
        "\n",
        "    # Plotten\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.imshow(x)\n",
        "    plt.title(f\"{name}: Klasse {label}, P={proba:.2f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "v5kgFJGZ8kXR",
        "outputId": "c3ae3918-d7cf-4d01-8569-73c4bc3c7c57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lz02YDRj-Hg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}